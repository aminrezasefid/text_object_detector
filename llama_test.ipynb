{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user01\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\user01\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Define your Hugging Face token\n",
    "HUGGINGFACE_TOKEN = \"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\"\n",
    "login(token=HUGGINGFACE_TOKEN)\n",
    "# Log in to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:20<00:00,  5.05s/it]\n",
      "Some parameters are on the meta device device because they were offloaded to the cpu.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "# outputs = pipeline(\n",
    "#     messages,\n",
    "#     max_new_tokens=100,\n",
    "#     eos_token_id=terminators,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.6,\n",
    "#     top_p=0.9,\n",
    "# )\n",
    "# print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"objects.csv\")\n",
    "ImgId_cap_df=df[[\"image_ids\",\"captions\"]].iloc[:50]\n",
    "cap_Img_id_dict={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ImgId_cap_df.iterrows():\n",
    "    cap_Img_id_dict[item[1][\"captions\"]]=item[1][\"image_ids\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cap_Img_id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "terminators = [\n",
    "            pipeline.tokenizer.eos_token_id,\n",
    "            pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "         ]\n",
    "batch_size=5\n",
    "object_extracted_dict={\"image_ids\":[],\"captions\":[],\"objects\":[]}\n",
    "pipeline.tokenizer.pad_token_id = pipeline.model.config.eos_token_id\n",
    "pipeline.tokenizer.padding_side='right'\n",
    "outputs=[]\n",
    "for i in range(0,len(cap_Img_id_dict.keys()),batch_size):\n",
    "    captions=list(cap_Img_id_dict.keys())[i:i+batch_size]\n",
    "    prompt_list=[]\n",
    "    for caption in captions:\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": \"Your are object dector but in the text context instead of image\\\n",
    "              just give the objects without adjectives in the sentence with comma seperated and nothing more.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{caption}\"}\n",
    "        ]\n",
    "        # prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        #         message, \n",
    "        #         tokenize=False, \n",
    "        #         add_generation_prompt=True,\n",
    "        # )\n",
    "        prompt_list.append(message)\n",
    "    outputs .append( pipeline(\n",
    "     prompt_list,\n",
    "     max_new_tokens=15,\n",
    "     eos_token_id=terminators,\n",
    "     do_sample=True,\n",
    "     temperature=0.2,\n",
    "     top_p=0.9,\n",
    "     batch_size=batch_size))\n",
    "# print(outputs[0][\"generated_text\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(outputs)):\n",
    "    for j in range(len(outputs[i])):\n",
    "        cap=outputs[i][j][0][\"generated_text\"][1][\"content\"]\n",
    "        img_id=cap_Img_id_dict[cap]\n",
    "        objects=outputs[i][j][0][\"generated_text\"][2][\"content\"].split(\"assistant\\n\\n\")[-1].split(\", \")\n",
    "        object_extracted_dict[\"image_ids\"].append(img_id)\n",
    "        object_extracted_dict[\"captions\"].append(cap)\n",
    "        object_extracted_dict[\"objects\"].append(objects)\n",
    "pd.DataFrame.from_dict(object_extracted_dict).to_csv(\"objects4.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sentence:a bicycle replica with a clock as the front wheel\n",
    "objects:bicycle, replica, clock\n",
    "\n",
    "sentence:a messy bathroom countertop perched atop black cabinetry.\n",
    "objects:bathroom, countertop, cabinetry\n",
    "\n",
    "sentence:cars try to maneuver into parking spaces along a densely packed city street. \n",
    "objects:cars, parking spaces, city street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
